{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with PyTorch Step-by-Step: A Beginner's Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    import requests\n",
    "    url = 'https://raw.githubusercontent.com/dvgodoy/PyTorchStepByStep/master/config.py'\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open('config.py', 'wb').write(r.content)    \n",
    "except ModuleNotFoundError:\n",
    "    pass\n",
    "\n",
    "from config import *\n",
    "config_chapter1()\n",
    "# This is needed to render the plots in this chapter\n",
    "from plots.chapter1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Regression Problem\n",
    "\n",
    "$$\n",
    "\\Large y = b + w x + \\epsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_b = 1\n",
    "true_w = 2\n",
    "N = 100\n",
    "\n",
    "# Data Generation\n",
    "np.random.seed(42)\n",
    "x = np.random.rand(N, 1)\n",
    "epsilon = (.1 * np.random.randn(N, 1))\n",
    "y = true_b + true_w * x + epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffles the indices\n",
    "idx = np.arange(N)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "# Uses first 80 random indices for train\n",
    "train_idx = idx[:int(N*.8)]\n",
    "# Uses the remaining indices for validation\n",
    "val_idx = idx[int(N*.8):]\n",
    "\n",
    "# Generates train and validation sets\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_val, y_val = x[val_idx], y[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 864x432 with 2 Axes>,\n",
       " array([<AxesSubplot:title={'center':'Generated Data - Train'}, xlabel='x', ylabel='y'>,\n",
       "        <AxesSubplot:title={'center':'Generated Data - Validation'}, xlabel='x', ylabel='y'>],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure1(x_train, y_train, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Random Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49671415] [-0.1382643]\n"
     ]
    }
   ],
   "source": [
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "np.random.seed(42)\n",
    "b = np.random.randn(1)\n",
    "w = np.random.randn(1)\n",
    "\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Compute Model's Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Computes our model's predicted output - forward pass\n",
    "yhat = b + w * x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Compute the Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7421577700550976\n"
     ]
    }
   ],
   "source": [
    "# Step 2 - Computing the loss\n",
    "# We are using ALL data points, so this is BATCH gradient\n",
    "# descent. How wrong is our model? That's the error!\n",
    "error = (yhat - y_train)\n",
    "\n",
    "# It is a regression, so it computes mean squared error (MSE)\n",
    "loss = (error ** 2).mean()\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Compute the Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.044811379650508 -1.8337537171510832\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "b_grad = 2 * error.mean()\n",
    "w_grad = 2 * (x_train * error).mean()\n",
    "print(b_grad, w_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Update the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49671415] [-0.1382643]\n",
      "[0.80119529] [0.04511107]\n"
     ]
    }
   ],
   "source": [
    "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
    "lr = 0.1\n",
    "print(b, w)\n",
    "\n",
    "# Step 4 - Updates parameters using gradients and \n",
    "# the learning rate\n",
    "b = b - lr * b_grad\n",
    "w = w - lr * w_grad\n",
    "\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Rinse and Repeat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go back to Step 1 and run observe how your parameters b and w change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression in Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49671415] [-0.1382643]\n",
      "[1.02354094] [1.96896411]\n"
     ]
    }
   ],
   "source": [
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "np.random.seed(42)\n",
    "b = np.random.randn(1)\n",
    "w = np.random.randn(1)\n",
    "\n",
    "print(b, w)\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\"-like Greek letter\n",
    "lr = 0.1\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Step 1 - Computes model's predicted output - forward pass\n",
    "    yhat = b + w * x_train\n",
    "    \n",
    "    # Step 2 - Computes the loss\n",
    "    # We are using ALL data points, so this is BATCH gradient\n",
    "    # descent. How wrong is our model? That's the error!   \n",
    "    error = (yhat - y_train)\n",
    "    # It is a regression, so it computes mean squared error (MSE)\n",
    "    loss = (error ** 2).mean()\n",
    "    \n",
    "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "    b_grad = 2 * error.mean()\n",
    "    w_grad = 2 * (x_train * error).mean()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and \n",
    "    # the learning rate\n",
    "    b = b - lr * b_grad\n",
    "    w = w - lr * w_grad\n",
    "    \n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.02354075] [1.96896447]\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check: do we get the same results as our\n",
    "# gradient descent?\n",
    "linr = LinearRegression()\n",
    "linr.fit(x_train, y_train)\n",
    "print(linr.intercept_, linr.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = figure3(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1416)\n",
      "tensor([1, 2, 3])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[[-4.7606e-01,  1.3377e-01,  1.0384e+00,  6.3022e-01],\n",
      "         [-3.5036e-01,  8.7575e-01, -1.7877e-03,  3.9785e-01],\n",
      "         [ 1.9548e+00, -2.0401e+00, -8.9417e-02, -1.6122e+00]],\n",
      "\n",
      "        [[ 9.4842e-01, -5.8314e-01,  5.5276e-01, -7.3498e-01],\n",
      "         [ 2.1495e-01,  5.0106e-01, -7.4799e-01, -5.3666e-02],\n",
      "         [ 9.6741e-01,  1.6436e-01,  1.2670e+00, -3.9991e-01]]])\n"
     ]
    }
   ],
   "source": [
    "scalar = torch.tensor(3.14159)\n",
    "vector = torch.tensor([1, 2, 3])\n",
    "matrix = torch.ones((2, 3), dtype=torch.float)\n",
    "tensor = torch.randn((2, 3, 4), dtype=torch.float)\n",
    "\n",
    "print(scalar)\n",
    "print(vector)\n",
    "print(matrix)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4]) torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(tensor.size(), tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(scalar.size(), scalar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 2., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# We get a tensor with a different shape but it still is\n",
    "# the SAME tensor\n",
    "same_matrix = matrix.view(1,6)\n",
    "# If we change one of its elements...\n",
    "same_matrix[0, 1] = 2.\n",
    "# It changes both variables: matrix and same_matrix\n",
    "print(matrix)\n",
    "print(same_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_matrix.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 3., 1., 1., 1., 1.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_10868\\1277334554.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  different_matrix = matrix.new_tensor(matrix.view(1, 6))\n"
     ]
    }
   ],
   "source": [
    "# We can use \"new_tensor\" method to REALLY copy it into a new one\n",
    "different_matrix = matrix.new_tensor(matrix.view(1, 6))\n",
    "# Now, if we change one of its elements...\n",
    "different_matrix[0, 1] = 3.\n",
    "# The original tensor (matrix) is left untouched!\n",
    "# But we get a \"warning\" from PyTorch telling us \n",
    "# to use \"clone()\" instead!\n",
    "print(matrix)\n",
    "print(different_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 4., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Lets follow PyTorch's suggestion and use \"clone\" method\n",
    "another_matrix = matrix.view(1, 6).clone().detach()\n",
    "# Again, if we change one of its elements...\n",
    "another_matrix[0, 1] = 4.\n",
    "# The original tensor (matrix) is left untouched!\n",
    "print(matrix)\n",
    "print(another_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data, Devices and CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tensor = torch.as_tensor(x_train)\n",
    "x_train.dtype, x_train_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_tensor = x_train_tensor.float()\n",
    "float_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_array = np.array([1, 2, 3])\n",
    "dummy_tensor = torch.as_tensor(dummy_array)\n",
    "# Modifies the numpy array\n",
    "dummy_array[1] = 0\n",
    "# Tensor gets modified too...\n",
    "dummy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining your device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1060 6GB\n"
     ]
    }
   ],
   "source": [
    "n_cudas = torch.cuda.device_count()\n",
    "for i in range(n_cudas):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7713], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_tensor = torch.as_tensor(x_train).to(device)\n",
    "gpu_tensor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Our data was in Numpy arrays, but we need to transform them \n",
    "# into PyTorch's Tensors and then we send them to the \n",
    "# chosen device\n",
    "x_train_tensor = torch.as_tensor(x_train).float().to(device)\n",
    "y_train_tensor = torch.as_tensor(y_train).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# Here we can see the difference - notice that .type() is more\n",
    "# useful since it also tells us WHERE the tensor is (device)\n",
    "print(type(x_train), type(x_train_tensor), x_train_tensor.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m back_to_numpy \u001b[38;5;241m=\u001b[39m \u001b[43mx_train_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "back_to_numpy = x_train_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_to_numpy = x_train_tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# FIRST\n",
    "# Initializes parameters \"b\" and \"w\" randomly, ALMOST as we\n",
    "# did in Numpy since we want to apply gradient descent on\n",
    "# these parameters we need to set REQUIRES_GRAD = TRUE\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], device='cuda:0', grad_fn=<ToCopyBackward0>) tensor([0.1288], device='cuda:0', grad_fn=<ToCopyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# SECOND\n",
    "# But what if we want to run it on a GPU? We could just\n",
    "# send them to device, right?\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
    "print(b, w)\n",
    "# Sorry, but NO! The to(device) \"shadows\" the gradient..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], device='cuda:0', requires_grad=True) tensor([0.1288], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# THIRD\n",
    "# We can either create regular tensors and send them to\n",
    "# the device (as we did with our data)\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, dtype=torch.float).to(device)\n",
    "w = torch.randn(1, dtype=torch.float).to(device)\n",
    "# and THEN set them as requiring gradients...\n",
    "b.requires_grad_()\n",
    "w.requires_grad_()\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# FINAL\n",
    "# We can specify the device at the moment of creation\n",
    "# RECOMMENDED!\n",
    "\n",
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.1940], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b+5\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Computes our model's predicted output - forward pass\n",
    "yhat = b + w * x_train_tensor\n",
    "\n",
    "# Step 2 - Computes the loss\n",
    "# We are using ALL data points, so this is BATCH gradient descent\n",
    "# How wrong is our model? That's the error! \n",
    "error = (yhat - y_train_tensor)\n",
    "# It is a regression, so it computes mean squared error (MSE)\n",
    "loss = (error ** 2).mean()\n",
    "\n",
    "# Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "# No more manual computation of gradients! \n",
    "# b_grad = 2 * error.mean()\n",
    "# w_grad = 2 * (x_tensor * error).mean()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True True\n",
      "False False\n"
     ]
    }
   ],
   "source": [
    "print(error.requires_grad, yhat.requires_grad, b.requires_grad, w.requires_grad)\n",
    "print(y_train_tensor.requires_grad, x_train_tensor.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.7762], device='cuda:0') tensor([-3.8878], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(b.grad, w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run the two cells above one more time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zero_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.], device='cuda:0'), tensor([0.], device='cuda:0'))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code will be placed *after* Step 4\n",
    "# (updating the parameters)\n",
    "b.grad.zero_(), w.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Sets learning rate - this is \"eta\" ~ the \"n\"-like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Step 1 - Computes model's predicted output - forward pass\n",
    "    yhat = b + w * x_train_tensor\n",
    "    \n",
    "    # Step 2 - Computes the loss\n",
    "    # We are using ALL data points, so this is BATCH gradient\n",
    "    # descent. How wrong is our model? That's the error!\n",
    "    error = (yhat - y_train_tensor)\n",
    "    # It is a regression, so it computes mean squared error (MSE)\n",
    "    loss = (error ** 2).mean()\n",
    "\n",
    "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "    # No more manual computation of gradients! \n",
    "    # b_grad = 2 * error.mean()\n",
    "    # w_grad = 2 * (x_tensor * error).mean()   \n",
    "    # We just tell PyTorch to work its way BACKWARDS \n",
    "    # from the specified loss!\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and \n",
    "    # the learning rate. But not so fast...\n",
    "    # FIRST ATTEMPT - just using the same code as before\n",
    "    # AttributeError: 'NoneType' object has no attribute 'zero_'\n",
    "    # b = b - lr * b.grad\n",
    "    # w = w - lr * w.grad\n",
    "    # print(b)\n",
    "\n",
    "    # SECOND ATTEMPT - using in-place Python assigment\n",
    "    # RuntimeError: a leaf Variable that requires grad\n",
    "    # has been used in an in-place operation.\n",
    "    # b -= lr * b.grad\n",
    "    # w -= lr * w.grad        \n",
    "    \n",
    "    # THIRD ATTEMPT - NO_GRAD for the win!\n",
    "    # We need to use NO_GRAD to keep the update out of\n",
    "    # the gradient computation. Why is that? It boils \n",
    "    # down to the DYNAMIC GRAPH that PyTorch uses...\n",
    "    with torch.no_grad():\n",
    "        b -= lr * b.grad\n",
    "        w -= lr * w.grad\n",
    "    \n",
    "    # PyTorch is \"clingy\" to its computed gradients, we\n",
    "    # need to tell it to let it go...\n",
    "    b.grad.zero_()\n",
    "    w.grad.zero_()\n",
    "    \n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is what we used in the THIRD ATTEMPT..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Computation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 5.0.0 (20220707.1540)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"222pt\" height=\"448pt\"\n",
       " viewBox=\"0.00 0.00 222.00 448.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 444)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-444 218,-444 218,4 -4,4\"/>\n",
       "<!-- 1627123004336 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1627123004336</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"133.5,-31 79.5,-31 79.5,0 133.5,0 133.5,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 1627108662480 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1627108662480</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"154,-86 59,-86 59,-67 154,-67 154,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\n",
       "</g>\n",
       "<!-- 1627108662480&#45;&gt;1627123004336 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>1627108662480&#45;&gt;1627123004336</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.5,-66.79C106.5,-60.07 106.5,-50.4 106.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110,-41.19 106.5,-31.19 103,-41.19 110,-41.19\"/>\n",
       "</g>\n",
       "<!-- 1627108662384 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1627108662384</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-141 62,-141 62,-122 151,-122 151,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
       "</g>\n",
       "<!-- 1627108662384&#45;&gt;1627108662480 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1627108662384&#45;&gt;1627108662480</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.5,-121.75C106.5,-114.8 106.5,-104.85 106.5,-96.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110,-96.09 106.5,-86.09 103,-96.09 110,-96.09\"/>\n",
       "</g>\n",
       "<!-- 1627108660944 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>1627108660944</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-196 62,-196 62,-177 151,-177 151,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 1627108660944&#45;&gt;1627108662384 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1627108660944&#45;&gt;1627108662384</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.5,-176.75C106.5,-169.8 106.5,-159.85 106.5,-151.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110,-151.09 106.5,-141.09 103,-151.09 110,-151.09\"/>\n",
       "</g>\n",
       "<!-- 1627108661040 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>1627108661040</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-251 62,-251 62,-232 151,-232 151,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 1627108661040&#45;&gt;1627108660944 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1627108661040&#45;&gt;1627108660944</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.5,-231.75C106.5,-224.8 106.5,-214.85 106.5,-206.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110,-206.09 106.5,-196.09 103,-206.09 110,-206.09\"/>\n",
       "</g>\n",
       "<!-- 1627108661904 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>1627108661904</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-306 0,-306 0,-287 101,-287 101,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 1627108661904&#45;&gt;1627108661040 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>1627108661904&#45;&gt;1627108661040</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.5,-286.98C67.69,-279.23 80.01,-267.58 89.97,-258.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"92.48,-260.59 97.34,-251.17 87.67,-255.5 92.48,-260.59\"/>\n",
       "</g>\n",
       "<!-- 1627123007712 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>1627123007712</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-373 23.5,-373 23.5,-342 77.5,-342 77.5,-373\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 1627123007712&#45;&gt;1627108661904 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1627123007712&#45;&gt;1627108661904</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-341.92C50.5,-334.22 50.5,-324.69 50.5,-316.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-316.25 50.5,-306.25 47,-316.25 54,-316.25\"/>\n",
       "</g>\n",
       "<!-- 1627108662192 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>1627108662192</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-306 119,-306 119,-287 208,-287 208,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 1627108662192&#45;&gt;1627108661040 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>1627108662192&#45;&gt;1627108661040</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M154.34,-286.98C146,-279.23 133.47,-267.58 123.32,-258.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.53,-255.42 115.82,-251.17 120.76,-260.54 125.53,-255.42\"/>\n",
       "</g>\n",
       "<!-- 1627108661808 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>1627108661808</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"214,-367 113,-367 113,-348 214,-348 214,-367\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-355\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 1627108661808&#45;&gt;1627108662192 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>1627108661808&#45;&gt;1627108662192</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.5,-347.79C163.5,-339.6 163.5,-327.06 163.5,-316.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167,-316.24 163.5,-306.24 160,-316.24 167,-316.24\"/>\n",
       "</g>\n",
       "<!-- 1627123171552 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>1627123171552</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"190.5,-440 136.5,-440 136.5,-409 190.5,-409 190.5,-440\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-416\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 1627123171552&#45;&gt;1627108661808 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>1627123171552&#45;&gt;1627108661808</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.5,-408.75C163.5,-399.39 163.5,-387.19 163.5,-377.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167,-377.02 163.5,-367.02 160,-377.02 167,-377.02\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x17ad73bde20>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "# Step 1 - Computes our model's predicted output - forward pass\n",
    "yhat = b + w * x_train_tensor\n",
    "\n",
    "# Step 2 - Computes the loss\n",
    "# We are using ALL data points, so this is BATCH gradient\n",
    "# descent. How wrong is our model? That's the error! \n",
    "error = (yhat - y_train_tensor)\n",
    "# It is a regression, so it computes mean squared error (MSE)\n",
    "loss = (error ** 2).mean()\n",
    "\n",
    "# We can try plotting the graph for any python variable: \n",
    "# yhat, error, loss...\n",
    "make_dot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 5.0.0 (20220707.1540)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"109pt\" height=\"271pt\"\n",
       " viewBox=\"0.00 0.00 109.00 271.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 267)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-267 105,-267 105,4 -4,4\"/>\n",
       "<!-- 1625689684784 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1625689684784</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"83,-31 18,-31 18,0 83,0 83,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (80, 1)</text>\n",
       "</g>\n",
       "<!-- 1627114742208 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1627114742208</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-86 6,-86 6,-67 95,-67 95,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 1627114742208&#45;&gt;1625689684784 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>1627114742208&#45;&gt;1625689684784</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.79C50.5,-60.07 50.5,-50.4 50.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-41.19 50.5,-31.19 47,-41.19 54,-41.19\"/>\n",
       "</g>\n",
       "<!-- 1627114742832 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1627114742832</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-141 6,-141 6,-122 95,-122 95,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 1627114742832&#45;&gt;1627114742208 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1627114742832&#45;&gt;1627114742208</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-121.75C50.5,-114.8 50.5,-104.85 50.5,-96.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-96.09 50.5,-86.09 47,-96.09 54,-96.09\"/>\n",
       "</g>\n",
       "<!-- 1627114745664 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>1627114745664</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-196 0,-196 0,-177 101,-177 101,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 1627114745664&#45;&gt;1627114742832 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1627114745664&#45;&gt;1627114742832</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-176.75C50.5,-169.8 50.5,-159.85 50.5,-151.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-151.09 50.5,-141.09 47,-151.09 54,-151.09\"/>\n",
       "</g>\n",
       "<!-- 1627123172352 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>1627123172352</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-263 23.5,-263 23.5,-232 77.5,-232 77.5,-263\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 1627123172352&#45;&gt;1627114745664 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1627123172352&#45;&gt;1627114745664</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-231.92C50.5,-224.22 50.5,-214.69 50.5,-206.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-206.25 50.5,-196.25 47,-206.25 54,-206.25\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x17ad798a5e0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_nograd = torch.randn(1, requires_grad=False, dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "yhat = b_nograd + w * x_train_tensor\n",
    "\n",
    "make_dot(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 5.0.0 (20220707.1540)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"326pt\" height=\"503pt\"\n",
       " viewBox=\"0.00 0.00 326.00 503.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 499)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-499 322,-499 322,4 -4,4\"/>\n",
       "<!-- 1627122993168 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1627122993168</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"242.5,-31 188.5,-31 188.5,0 242.5,0 242.5,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"215.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 1627106772064 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1627106772064</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"260,-86 171,-86 171,-67 260,-67 260,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"215.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 1627106772064&#45;&gt;1627122993168 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>1627106772064&#45;&gt;1627122993168</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M215.5,-66.79C215.5,-60.07 215.5,-50.4 215.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"219,-41.19 215.5,-31.19 212,-41.19 219,-41.19\"/>\n",
       "</g>\n",
       "<!-- 1626637090976 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1626637090976</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"225,-141 130,-141 130,-122 225,-122 225,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"177.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\n",
       "</g>\n",
       "<!-- 1626637090976&#45;&gt;1627106772064 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1626637090976&#45;&gt;1627106772064</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M183.77,-121.75C189.09,-114.34 196.86,-103.5 203.38,-94.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206.36,-96.26 209.34,-86.09 200.67,-92.18 206.36,-96.26\"/>\n",
       "</g>\n",
       "<!-- 1627106063984 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>1627106063984</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"205,-196 116,-196 116,-177 205,-177 205,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"160.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
       "</g>\n",
       "<!-- 1627106063984&#45;&gt;1626637090976 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1627106063984&#45;&gt;1626637090976</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.31,-176.75C165.56,-169.72 168.8,-159.62 171.62,-150.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"175.02,-151.68 174.75,-141.09 168.36,-149.54 175.02,-151.68\"/>\n",
       "</g>\n",
       "<!-- 1627108661856 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>1627108661856</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"205,-251 116,-251 116,-232 205,-232 205,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"160.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 1627108661856&#45;&gt;1627106063984 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1627108661856&#45;&gt;1627106063984</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M160.5,-231.75C160.5,-224.8 160.5,-214.85 160.5,-206.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"164,-206.09 160.5,-196.09 157,-206.09 164,-206.09\"/>\n",
       "</g>\n",
       "<!-- 1627108661568 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>1627108661568</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"205,-306 116,-306 116,-287 205,-287 205,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"160.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 1627108661568&#45;&gt;1627108661856 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>1627108661568&#45;&gt;1627108661856</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M160.5,-286.75C160.5,-279.8 160.5,-269.85 160.5,-261.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"164,-261.09 160.5,-251.09 157,-261.09 164,-261.09\"/>\n",
       "</g>\n",
       "<!-- 1627108660752 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>1627108660752</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-361 0,-361 0,-342 101,-342 101,-361\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 1627108660752&#45;&gt;1627108661568 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1627108660752&#45;&gt;1627108661568</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M68.17,-341.98C85.79,-333.5 113.08,-320.35 133.43,-310.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.02,-313.66 142.51,-306.17 131.98,-307.36 135.02,-313.66\"/>\n",
       "</g>\n",
       "<!-- 1627123171792 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>1627123171792</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-428 23.5,-428 23.5,-397 77.5,-397 77.5,-428\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-404\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 1627123171792&#45;&gt;1627108660752 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>1627123171792&#45;&gt;1627108660752</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-396.92C50.5,-389.22 50.5,-379.69 50.5,-371.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-371.25 50.5,-361.25 47,-371.25 54,-371.25\"/>\n",
       "</g>\n",
       "<!-- 1627108661616 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>1627108661616</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-361 119,-361 119,-342 208,-342 208,-361\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 1627108661616&#45;&gt;1627108661568 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>1627108661616&#45;&gt;1627108661568</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163,-341.75C162.61,-334.8 162.05,-324.85 161.55,-316.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"165.05,-315.88 160.99,-306.09 158.06,-316.27 165.05,-315.88\"/>\n",
       "</g>\n",
       "<!-- 1627108662144 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>1627108662144</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"267,-422 166,-422 166,-403 267,-403 267,-422\"/>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-410\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 1627108662144&#45;&gt;1627108661616 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>1627108662144&#45;&gt;1627108661616</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M208.68,-402.79C200.69,-393.91 188.11,-379.89 178.24,-368.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"180.64,-366.34 171.35,-361.24 175.43,-371.02 180.64,-366.34\"/>\n",
       "</g>\n",
       "<!-- 1627108660704 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>1627108660704</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"315,-361 226,-361 226,-342 315,-342 315,-361\"/>\n",
       "<text text-anchor=\"middle\" x=\"270.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 1627108662144&#45;&gt;1627108660704 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>1627108662144&#45;&gt;1627108660704</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M224.47,-402.79C232.6,-393.91 245.43,-379.89 255.48,-368.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"258.33,-370.98 262.5,-361.24 253.17,-366.26 258.33,-370.98\"/>\n",
       "</g>\n",
       "<!-- 1627123166320 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>1627123166320</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"243.5,-495 189.5,-495 189.5,-464 243.5,-464 243.5,-495\"/>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-471\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 1627123166320&#45;&gt;1627108662144 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>1627123166320&#45;&gt;1627108662144</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M216.5,-463.75C216.5,-454.39 216.5,-442.19 216.5,-432.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"220,-432.02 216.5,-422.02 213,-432.02 220,-432.02\"/>\n",
       "</g>\n",
       "<!-- 1627117076688 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>1627117076688</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"318,-196 223,-196 223,-177 318,-177 318,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"270.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\n",
       "</g>\n",
       "<!-- 1627117076688&#45;&gt;1627106772064 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>1627117076688&#45;&gt;1627106772064</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M266,-176.66C256.97,-158.93 236.5,-118.73 224.57,-95.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"227.57,-93.48 219.91,-86.16 221.33,-96.66 227.57,-93.48\"/>\n",
       "</g>\n",
       "<!-- 1627108662720 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>1627108662720</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"315,-306 226,-306 226,-287 315,-287 315,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"270.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 1627108662720&#45;&gt;1627117076688 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>1627108662720&#45;&gt;1627117076688</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M270.5,-286.66C270.5,-269.17 270.5,-229.8 270.5,-206.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"274,-206.16 270.5,-196.16 267,-206.16 274,-206.16\"/>\n",
       "</g>\n",
       "<!-- 1627108660704&#45;&gt;1627108662720 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>1627108660704&#45;&gt;1627108662720</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M270.5,-341.75C270.5,-334.8 270.5,-324.85 270.5,-316.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"274,-316.09 270.5,-306.09 267,-316.09 274,-316.09\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x17ab98a0ac0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "yhat = b + w * x_train_tensor\n",
    "error = yhat - y_train_tensor\n",
    "loss = (error ** 2).mean()\n",
    "\n",
    "# this makes no sense!!\n",
    "if loss > 0:\n",
    "    yhat2 = w * x_train_tensor\n",
    "    error2 = yhat2 - y_train_tensor\n",
    "    \n",
    "# neither does this :-)\n",
    "loss += error2.mean()\n",
    "\n",
    "make_dot(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step / zero_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a SGD optimizer to update the parameters\n",
    "optimizer = optim.SGD([b, w], lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Sets learning rate - this is \"eta\" ~ the \"n\"-like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters\n",
    "optimizer = optim.SGD([b, w], lr=lr)\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Step 1 - Computes model's predicted output - forward pass\n",
    "    yhat = b + w * x_train_tensor\n",
    "    \n",
    "    # Step 2 - Computes the loss\n",
    "    # We are using ALL data points, so this is BATCH gradient \n",
    "    # descent. How wrong is our model? That's the error! \n",
    "    error = (yhat - y_train_tensor)\n",
    "    # It is a regression, so it computes mean squared error (MSE)\n",
    "    loss = (error ** 2).mean()\n",
    "\n",
    "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and \n",
    "    # the learning rate. No more manual update!\n",
    "    # with torch.no_grad():\n",
    "    #     b -= lr * b.grad\n",
    "    #     w -= lr * w.grad\n",
    "    optimizer.step()\n",
    "    \n",
    "    # No more telling Pytorch to let gradients go!\n",
    "    # b.grad.zero_()\n",
    "    # w.grad.zero_()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1700)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a random example to illustrate the loss function\n",
    "predictions = torch.tensor([0.5, 1.0])\n",
    "labels = torch.tensor([2.0, 1.3])\n",
    "loss_fn(predictions, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Sets learning rate - this is \"eta\" ~ the \"n\"-like\n",
    "# Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters\n",
    "optimizer = optim.SGD([b, w], lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Step 1 - Computes model's predicted output - forward pass\n",
    "    yhat = b + w * x_train_tensor\n",
    "    \n",
    "    # Step 2 - Computes the loss\n",
    "    # No more manual loss!\n",
    "    # error = (yhat - y_train_tensor)\n",
    "    # loss = (error ** 2).mean()\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "\n",
    "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and\n",
    "    # the learning rate\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0080, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [76]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "loss.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.00804466, dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008044655434787273 0.008044655434787273\n"
     ]
    }
   ],
   "source": [
    "print(loss.item(), loss.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManualLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # To make \"b\" and \"w\" real parameters of the model,\n",
    "        # we need to wrap them with nn.Parameter\n",
    "        self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        self.w = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Computes the outputs / predictions\n",
    "        return self.b + self.w * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# Creates a \"dummy\" instance of our ManualLinearRegression model\n",
    "dummy = ManualLinearRegression()\n",
    "list(dummy.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('b', tensor([0.3367])), ('w', tensor([0.1288]))])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {0: {'momentum_buffer': None}, 1: {'momentum_buffer': None}},\n",
       " 'param_groups': [{'lr': 0.1,\n",
       "   'momentum': 0,\n",
       "   'dampening': 0,\n",
       "   'weight_decay': 0,\n",
       "   'nesterov': False,\n",
       "   'maximize': False,\n",
       "   'foreach': None,\n",
       "   'params': [0, 1]}]}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "# Creates a \"dummy\" instance of our ManualLinearRegression model\n",
    "# and sends it to the device\n",
    "dummy = ManualLinearRegression().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 1.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('b', tensor([1.0235], device='cuda:0')), ('w', tensor([1.9690], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# Sets learning rate - this is \"eta\" ~ the \"n\"-like\n",
    "# Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = ManualLinearRegression().to(device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters \n",
    "# (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train() # What is this?!?\n",
    "\n",
    "    # Step 1 - Computes model's predicted output - forward pass\n",
    "    # No more manual prediction!\n",
    "    yhat = model(x_train_tensor)\n",
    "    \n",
    "    # Step 2 - Computes the loss\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "\n",
    "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and\n",
    "    # the learning rate\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "# We can also inspect its parameters using its state_dict\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Never forget to include model.train() in your training loop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(1, 1)\n",
    "linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([[-0.2191]])), ('bias', tensor([0.2018]))])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 1.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Instead of our custom parameters, we use a Linear model\n",
    "        # with single input and single output\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # Now it only takes a call\n",
    "        self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.7645]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.8300], device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "dummy = MyLinearRegression().to(device)\n",
    "list(dummy.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight', tensor([[0.7645]], device='cuda:0')),\n",
       "             ('linear.bias', tensor([0.8300], device='cuda:0'))])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 1.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[0.7645]], device='cuda:0')),\n",
       "             ('0.bias', tensor([0.8300], device='cuda:0'))])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# Alternatively, you can use a Sequential model\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[ 0.4414,  0.4792, -0.1353],\n",
       "                      [ 0.5304, -0.1265,  0.1165],\n",
       "                      [-0.2811,  0.3391,  0.5090],\n",
       "                      [-0.4236,  0.5018,  0.1081],\n",
       "                      [ 0.4266,  0.0782,  0.2784]], device='cuda:0')),\n",
       "             ('0.bias',\n",
       "              tensor([-0.0815,  0.4451,  0.0853, -0.2695,  0.1472], device='cuda:0')),\n",
       "             ('1.weight',\n",
       "              tensor([[-0.2060, -0.0524, -0.1816,  0.2967, -0.3530]], device='cuda:0')),\n",
       "             ('1.bias', tensor([-0.2062], device='cuda:0'))])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# Building the model from the figure above\n",
    "model = nn.Sequential(nn.Linear(3, 5), nn.Linear(5, 1)).to(device)\n",
    "\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (layer1): Linear(in_features=3, out_features=5, bias=True)\n",
       "  (layer2): Linear(in_features=5, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# Building the model from the figure above\n",
    "model = nn.Sequential()\n",
    "model.add_module('layer1', nn.Linear(3, 5))\n",
    "model.add_module('layer2', nn.Linear(5, 1))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting It All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_preparation/v0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_preparation/v0.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Our data was in Numpy arrays, but we need to transform them\n",
    "# into PyTorch's Tensors and then we send them to the \n",
    "# chosen device\n",
    "x_train_tensor = torch.as_tensor(x_train).float().to(device)\n",
    "y_train_tensor = torch.as_tensor(y_train).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v0.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configurtion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_configuration/v0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v0.py\n",
    "\n",
    "# This is redundant now, but it won't be when we introduce\n",
    "# Datasets...\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\"-like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters \n",
    "# (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v0.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v0.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Sets model to TRAIN mode\n",
    "    model.train()\n",
    "\n",
    "    # Step 1 - Computes model's predicted output - forward pass\n",
    "    yhat = model(x_train_tensor)\n",
    "    \n",
    "    # Step 2 - Computes the loss\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "\n",
    "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and \n",
    "    # the learning rate\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v0.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9690]], device='cuda:0')), ('0.bias', tensor([1.0235], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
